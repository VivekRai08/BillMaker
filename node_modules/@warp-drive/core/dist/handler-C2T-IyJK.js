import { J as ReactiveDocument } from "./request-state-CjLph1LP.js";
import { SkipCache, EnableHydration } from './types/request.js';
import { macroCondition, getGlobalConfig } from '@embroider/macros';
const MUTATION_OPS = new Set(['createRecord', 'updateRecord', 'deleteRecord']);
function calcShouldFetch(store, request, hasCachedValue, identifier) {
  const {
    cacheOptions
  } = request;
  return request.op && MUTATION_OPS.has(request.op) || cacheOptions?.reload || !hasCachedValue || (store.lifetimes && identifier ? store.lifetimes.isHardExpired(identifier, store) : false);
}
function calcShouldBackgroundFetch(store, request, willFetch, identifier) {
  const {
    cacheOptions
  } = request;
  return cacheOptions?.backgroundReload || (store.lifetimes && identifier ? store.lifetimes.isSoftExpired(identifier, store) : false);
}
function isMutation(request) {
  return Boolean(request.op && MUTATION_OPS.has(request.op));
}
function isCacheAffecting(document) {
  if (!isMutation(document.request)) {
    return true;
  }
  // a mutation combined with a 204 has no cache impact when no known records were involved
  // a createRecord with a 201 with an empty response and no known records should similarly
  // have no cache impact

  if (document.request.op === 'createRecord' && document.response?.status === 201) {
    return document.content ? Object.keys(document.content).length > 0 : false;
  }
  return document.response?.status !== 204;
}
function isAggregateError(error) {
  return error instanceof AggregateError || error.name === 'AggregateError' && Array.isArray(error.errors);
}
// TODO @runspired, consider if we should deep freeze errors (potentially only in debug) vs cloning them
function cloneError(error) {
  const isAggregate = isAggregateError(error);
  const cloned = isAggregate ? new AggregateError(structuredClone(error.errors), error.message) : new Error(error.message);
  cloned.stack = error.stack;
  cloned.error = error.error;

  // copy over enumerable properties
  Object.assign(cloned, error);
  return cloned;
}
function getPriority(identifier, deduped, priority) {
  if (identifier) {
    const existing = deduped.get(identifier);
    if (existing) {
      return existing.priority;
    }
  }
  return priority;
}

/**
 * A CacheHandler that adds support for using an WarpDrive Cache with a RequestManager.
 *
 * This handler will only run when a request has supplied a `store` instance. Requests
 * issued by the store via `store.request()` will automatically have the `store` instance
 * attached to the request.
 *
 * ```ts
 * requestManager.request({
 *   store: store,
 *   url: '/api/posts',
 *   method: 'GET'
 * });
 * ```
 *
 * When this handler elects to handle a request, it will return the raw `StructuredDocument`
 * unless the request has `[EnableHydration]` set to `true`. In this case, the handler will
 * return a `Document` instance that will automatically update the UI when the cache is updated
 * in the future and will hydrate any identifiers in the StructuredDocument into Record instances.
 *
 * When issuing a request via the store, [EnableHydration] is automatically set to `true`. This
 * means that if desired you can issue requests that utilize the cache without needing to also
 * utilize Record instances if desired.
 *
 * Said differently, you could elect to issue all requests via a RequestManager, without ever using
 * the store directly, by setting [EnableHydration] to `true` and providing a store instance. Not
 * necessarily the most useful thing, but the decoupled nature of the RequestManager and incremental-feature
 * approach of WarpDrive allows for this flexibility.
 *
 * ```ts
 * import { EnableHydration } from '@warp-drive/core/types/request';
 *
 * requestManager.request({
 *   store: store,
 *   url: '/api/posts',
 *   method: 'GET',
 *   [EnableHydration]: true
 * });
 *
 */
const CacheHandler = {
  request(context, next) {
    // if we have no cache or no cache-key skip cache handling
    if (!context.request.store || context.request.cacheOptions?.[SkipCache]) {
      return next(context.request);
    }
    const {
      store
    } = context.request;
    const identifier = store.identifierCache.getOrCreateDocumentIdentifier(context.request);
    if (identifier) {
      context.setIdentifier(identifier);
    }

    // used to dedupe existing requests that match
    const DEDUPE = store.requestManager._deduped;
    const activeRequest = identifier && DEDUPE.get(identifier);
    const peeked = identifier ? store.cache.peekRequest(identifier) : null;

    // determine if we should skip cache
    if (calcShouldFetch(store, context.request, !!peeked, identifier)) {
      if (activeRequest) {
        activeRequest.priority = {
          blocking: true
        };
        return activeRequest.promise;
      }
      let promise = fetchContentAndHydrate(next, context, identifier, {
        blocking: true
      });
      if (identifier) {
        promise = promise.finally(() => {
          DEDUPE.delete(identifier);
          store.notifications.notify(identifier, 'state');
        });
        DEDUPE.set(identifier, {
          priority: {
            blocking: true
          },
          promise
        });
        store.notifications.notify(identifier, 'state');
      }
      return promise;
    }

    // if we have not skipped cache, determine if we should update behind the scenes
    if (calcShouldBackgroundFetch(store, context.request, false, identifier)) {
      let promise = activeRequest?.promise || fetchContentAndHydrate(next, context, identifier, {
        blocking: false
      });
      if (identifier && !activeRequest) {
        promise = promise.finally(() => {
          DEDUPE.delete(identifier);
          store.notifications.notify(identifier, 'state');
        });
        DEDUPE.set(identifier, {
          priority: {
            blocking: false
          },
          promise
        });
        store.notifications.notify(identifier, 'state');
      }
      store.requestManager._pending.set(context.id, promise);
    }
    macroCondition(getGlobalConfig().WarpDrive.env.DEBUG) ? (test => {
      if (!test) {
        throw new Error(`Expected a peeked request to be present`);
      }
    })(peeked) : {};
    const shouldHydrate = context.request[EnableHydration] || false;
    context.setResponse(peeked.response);
    if ('error' in peeked) {
      const content = shouldHydrate ? maybeUpdateUiObjects(store, context.request, {
        shouldHydrate,
        identifier
      }, peeked.content) : peeked.content;
      const newError = cloneError(peeked);
      newError.content = content;
      throw newError;
    }
    const result = shouldHydrate ? maybeUpdateUiObjects(store, context.request, {
      shouldHydrate,
      identifier
    }, peeked.content) : peeked.content;
    return result;
  }
};
function maybeUpdateUiObjects(store, request, options, document) {
  const {
    identifier
  } = options;
  if (!document || !options.shouldHydrate) {
    macroCondition(getGlobalConfig().WarpDrive.env.DEBUG) ? (test => {
      if (!test) {
        throw new Error(`The CacheHandler expected response content but none was found`);
      }
    })(!options.shouldHydrate) : {};
    return document ?? null;
  }
  if (identifier) {
    return store._instanceCache.getDocument(identifier);
  }

  // if we don't have an identifier, we give the document
  // its own local cache
  return new ReactiveDocument(store, null, {
    request,
    document
  });
}
function updateCacheForSuccess(store, request, options, document) {
  let response = null;
  if (isMutation(request)) {
    const record = request.data?.record || request.records?.[0];
    if (record) {
      response = store.cache.didCommit(record, document);

      // a mutation combined with a 204 has no cache impact when no known records were involved
      // a createRecord with a 201 with an empty response and no known records should similarly
      // have no cache impact
    } else if (isCacheAffecting(document)) {
      response = store.cache.put(document);
    }
  } else {
    response = store.cache.put(document);
  }
  return maybeUpdateUiObjects(store, request, options, response);
}
function handleFetchSuccess(store, context, options, document) {
  const {
    request
  } = context;
  store.requestManager._pending.delete(context.id);
  store._enableAsyncFlush = true;
  let response;
  store._join(() => {
    response = updateCacheForSuccess(store, request, options, document);
  });
  store._enableAsyncFlush = null;
  if (store.lifetimes?.didRequest) {
    store.lifetimes.didRequest(context.request, document.response, options.identifier, store);
  }
  const finalPriority = getPriority(options.identifier, store.requestManager._deduped, options.priority);
  if (finalPriority.blocking) {
    return response;
  } else {
    store.notifications._flush();
  }
}
function updateCacheForError(store, context, options, error) {
  let response;
  if (isMutation(context.request)) {
    // TODO similar to didCommit we should spec this to be similar to cache.put for handling full response
    // currently we let the response remain undefiend.
    const errors = error && error.content && typeof error.content === 'object' && 'errors' in error.content && Array.isArray(error.content.errors) ? error.content.errors : undefined;
    const record = context.request.data?.record || context.request.records?.[0];
    store.cache.commitWasRejected(record, errors);
  } else {
    response = store.cache.put(error);
    return maybeUpdateUiObjects(store, context.request, options, response);
  }
}
function handleFetchError(store, context, options, error) {
  store.requestManager._pending.delete(context.id);
  if (context.request.signal?.aborted) {
    throw error;
  }
  store._enableAsyncFlush = true;
  let response;
  store._join(() => {
    response = updateCacheForError(store, context, options, error);
  });
  store._enableAsyncFlush = null;
  if (options.identifier && store.lifetimes?.didRequest) {
    store.lifetimes.didRequest(context.request, error.response, options.identifier, store);
  }
  if (isMutation(context.request)) {
    throw error;
  }
  const finalPriority = getPriority(options.identifier, store.requestManager._deduped, options.priority);
  if (finalPriority.blocking) {
    const newError = cloneError(error);
    newError.content = response;
    throw newError;
  } else {
    store.notifications._flush();
  }
}
function fetchContentAndHydrate(next, context, identifier, priority) {
  const {
    store
  } = context.request;
  const shouldHydrate = context.request[EnableHydration] || false;
  const options = {
    shouldHydrate,
    identifier,
    priority
  };
  let isMut = false;
  if (isMutation(context.request)) {
    isMut = true;
    // TODO should we handle multiple records in request.records by iteratively calling willCommit for each
    const record = context.request.data?.record || context.request.records?.[0];
    macroCondition(getGlobalConfig().WarpDrive.env.DEBUG) ? (test => {
      if (!test) {
        throw new Error(`Expected to receive a list of records included in the ${context.request.op} request`);
      }
    })(record || !shouldHydrate) : {};
    if (record) {
      store.cache.willCommit(record, context);
    }
  }
  if (store.lifetimes?.willRequest) {
    store.lifetimes.willRequest(context.request, identifier, store);
  }
  const promise = next(context.request).then(document => {
    return handleFetchSuccess(store, context, options, document);
  }, error => {
    return handleFetchError(store, context, options, error);
  });
  if (!isMut) {
    return promise;
  }
  macroCondition(getGlobalConfig().WarpDrive.env.DEBUG) ? (test => {
    if (!test) {
      throw new Error(`Expected a mutation`);
    }
  })(isMutation(context.request)) : {};

  // for mutations we need to enqueue the promise with the requestStateService
  // TODO should we enque a request per record in records?
  const record = context.request.data?.record || context.request.records?.[0];
  return store._requestCache._enqueue(promise, {
    data: [{
      op: 'saveRecord',
      recordIdentifier: record,
      options: undefined
    }]
  });
}
export { CacheHandler as C };