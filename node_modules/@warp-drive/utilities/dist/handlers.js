import { macroCondition, getGlobalConfig } from '@embroider/macros';
function isCompressibleMethod(method) {
  return method === 'POST' || method === 'PUT' || method === 'PATCH' || method === 'DELETE';
}
const SupportsRequestStreams = (() => {
  let duplexAccessed = false;
  const hasContentType = new Request('', {
    body: new ReadableStream(),
    method: 'POST',
    // @ts-expect-error untyped
    get duplex() {
      duplexAccessed = true;
      return 'half';
    }
  }).headers.has('Content-Type');
  return duplexAccessed && !hasContentType;
})();

/**
 * Options for configuring the AutoCompress handler.
 *
 */

const DEFAULT_CONSTRAINTS = {
  Blob: 1000,
  ArrayBuffer: 1000,
  TypedArray: 1000,
  DataView: 1000,
  String: 1000
};
const TypedArray = Object.getPrototypeOf(Uint8Array.prototype);

/**
 * A request handler that automatically compresses the request body
 * if the request body is a string, array buffer, blob, or form data.
 *
 * This uses the [CompressionStream API](https://developer.mozilla.org/en-US/docs/Web/API/CompressionStream)
 *
 * The compression format as well as the kinds of data to compress can be
 * configured using the `format` and `constraints` options.
 *
 * ```diff
 * +import { AutoCompress } from '@ember-data/request-utils/handlers';
 * import Fetch from '@ember-data/request/fetch';
 * import RequestManager from '@ember-data/request';
 * import Store from '@ember-data/store';
 *
 * class AppStore extends Store {
 *   requestManager = new RequestManager()
 *     .use([
 * +       new AutoCompress(),
 *        Fetch
 *     ]);
 * }
 * ```
 *
 * @class AutoCompress
 * @public
 * @since 5.5.0
 */
class AutoCompress {
  constructor(options = {}) {
    const opts = {
      format: options.format ?? 'gzip',
      constraints: Object.assign({}, DEFAULT_CONSTRAINTS, options.constraints),
      allowStreaming: options.allowStreaming ?? false,
      forceStreaming: options.forceStreaming ?? false
    };
    this.options = opts;
  }
  request({
    request
  }, next) {
    const {
      constraints
    } = this.options;
    const {
      body
    } = request;
    const shouldCompress = isCompressibleMethod(request.method) && request.options?.compress !== false && (
    // prettier-ignore
    request.options?.compress ? true : typeof body === 'string' || body instanceof String ? canCompress('String', constraints, body.length) : body instanceof Blob ? canCompress('Blob', constraints, body.size) : body instanceof ArrayBuffer ? canCompress('ArrayBuffer', constraints, body.byteLength) : body instanceof DataView ? canCompress('DataView', constraints, body.byteLength) : body instanceof TypedArray ? canCompress('TypedArray', constraints, body.byteLength) : false);
    if (!shouldCompress) return next(request);

    // A convenient way to convert all of the supported body types to a readable
    // stream is to use a `Response` object body
    const response = new Response(request.body);
    const stream = response.body?.pipeThrough(new CompressionStream(this.options.format));
    const headers = new Headers(request.headers);
    headers.set('Content-Encoding', encodingForFormat(this.options.format));

    //
    // For browsers that support it, `fetch` can receive a `ReadableStream` as
    // the body, so all we need to do is to create a new `ReadableStream` and
    // compress it on the fly
    //
    const forceStreaming = request.options?.forceStreaming ?? this.options.forceStreaming;
    const allowStreaming = request.options?.allowStreaming ?? this.options.allowStreaming;
    if (forceStreaming || SupportsRequestStreams && allowStreaming) {
      const req = Object.assign({}, request, {
        body: stream,
        headers
      });
      if (SupportsRequestStreams) {
        // @ts-expect-error untyped
        req.duplex = 'half';
      }
      return next(req);

      //
      // For non-chromium browsers, we have to "pull" the stream to get the final
      // bytes and supply the final byte array as the new request body.
      //
    }

    // we need to pull the stream to get the final bytes
    const resp = new Response(stream);
    return resp.blob().then(blob => {
      const req = Object.assign({}, request, {
        body: blob,
        headers
      });
      return next(req);
    });
  }
}
function canCompress(type, constraints, size) {
  // if we have a value of 0, we can compress anything
  if (constraints[type] === 0) return true;
  if (constraints[type] === -1) return false;
  return size >= constraints[type];
}
function encodingForFormat(format) {
  switch (format) {
    case 'gzip':
    case 'deflate':
    case 'deflate-raw':
      return format;
    default:
      macroCondition(getGlobalConfig().WarpDrive.env.DEBUG) ? (test => {
        {
          throw new Error(`Unsupported compression format: ${format}`);
        }
      })() : {};
      // @ts-expect-error - unreachable code is reachable in production
      return format;
  }
}

/**
 * If CheckFn returns true, the wrapped handler will be used.
 * If CheckFn returns false, the wrapped handler will be skipped.
 */

/**
 *
 * @public
 */
class Gate {
  constructor(handler, checkFn) {
    this.handler = handler;
    this.checkFn = checkFn;
  }
  request(context, next) {
    if (this.checkFn(context)) {
      return this.handler.request(context, next);
    }
    return next(context.request);
  }
}
if (typeof FastBoot === 'undefined') {
  globalThis.addEventListener('beforeunload', function () {
    sessionStorage.setItem('tab-closed', 'true');
  });
}
function getTabId() {
  if (typeof sessionStorage === 'undefined') {
    return crypto.randomUUID();
  }
  const tabId = sessionStorage.getItem('tab-id');
  if (tabId) {
    const tabClosed = sessionStorage.getItem('tab-closed');
    if (tabClosed === 'true') {
      return tabId;
    }

    // fall through to generate a new tab id
  }
  const newTabId = crypto.randomUUID();
  sessionStorage.setItem('tab-id', newTabId);
  return newTabId;
}

/**
 * A unique identifier for the current browser tab
 * useful for observability/tracing and deduping
 * across multiple tabs.
 */
const TAB_ID = getTabId();
/**
 * The epoch seconds at which the tab id was generated
 */
const TAB_ASSIGNED = Math.floor(Date.now() / 1000);

/**
 * Adds the `X-Amzn-Trace-Id` header to support observability
 * tooling around request routing.
 *
 * This makes use of the {@link TAB_ID} and {@link TAB_ASSIGNED}
 * to enable tracking the browser tab of origin across multiple requests.
 *
 * Follows the template: `Root=1-${now}-${uuidv4};TabId=1-${epochSeconds}-${tab-uuid}`
 */
function addTraceHeader(headers) {
  const now = Math.floor(Date.now() / 1000);
  headers.set('X-Amzn-Trace-Id', `Root=1-${now}-${crypto.randomUUID()};TabId=1-${TAB_ASSIGNED}-${TAB_ID}`);
  return headers;
}

/**
 * Source: https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/cloudfront-limits.html
 * As of 2024-12-05 the maximum URL length is 8192 bytes.
 *
 */
const MAX_URL_LENGTH = 8192;

/**
 * This assertion takes a URL and throws an error if the URL is longer than the maximum URL length.
 *
 * See also {@link MAX_URL_LENGTH}
 */
function assertInvalidUrlLength(url) {
  macroCondition(getGlobalConfig().WarpDrive.env.DEBUG) ? (test => {
    if (!test) {
      throw new Error(`URL length ${url?.length} exceeds the maximum URL length of ${MAX_URL_LENGTH} bytes.\n\nConsider converting this request query a \`/query\` endpoint instead of a GET, or upgrade the current endpoint to be able to receive a POST request directly (ideally specifying the header HTTP-Method-Override: QUERY)\n\nThe Invalid URL is:\n\n${url}`);
    }
  })(!url || url.length <= MAX_URL_LENGTH) : {};
}
export { AutoCompress, Gate, MAX_URL_LENGTH, SupportsRequestStreams, TAB_ASSIGNED, TAB_ID, addTraceHeader, assertInvalidUrlLength };